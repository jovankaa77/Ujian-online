# Multi-Modal Architecture - Sistem Ujian Online

## Multi-Modal Architecture Diagram

```mermaid
graph TB
    subgraph "Input Modalities"
        subgraph "Visual Input"
            Camera[ðŸ“· Camera Stream]
            ScreenCapture[ðŸ–¥ï¸ Screen Capture]
            FaceDetection[ðŸ‘¤ Face Detection]
            GestureRecognition[ðŸ‘‹ Gesture Recognition]
            EyeTracking[ðŸ‘ï¸ Eye Tracking]
        end
        
        subgraph "Audio Input"
            Microphone[ðŸŽ¤ Microphone Stream]
            VoiceDetection[ðŸ—£ï¸ Voice Activity Detection]
            SpeechRecognition[ðŸŽ¯ Speech Recognition]
            AudioAnalysis[ðŸŽµ Audio Pattern Analysis]
            NoiseDetection[ðŸ”Š Background Noise Detection]
        end
        
        subgraph "Text Input"
            KeyboardInput[âŒ¨ï¸ Keyboard Input]
            TextAnalysis[ðŸ“ Text Pattern Analysis]
            TypingBehavior[âš¡ Typing Behavior Analysis]
            LanguageDetection[ðŸŒ Language Detection]
        end
        
        subgraph "Behavioral Input"
            MouseMovement[ðŸ–±ï¸ Mouse Movement]
            ClickPatterns[ðŸ‘† Click Patterns]
            ScrollBehavior[ðŸ“œ Scroll Behavior]
            WindowInteraction[ðŸªŸ Window Interaction]
            TabSwitching[ðŸ”„ Tab Switching]
        end
        
        subgraph "Device Input"
            DeviceOrientation[ðŸ“± Device Orientation]
            ScreenResolution[ðŸ“ Screen Resolution]
            BatteryStatus[ðŸ”‹ Battery Status]
            NetworkStatus[ðŸŒ Network Status]
            SystemResources[ðŸ’¾ System Resources]
        end
    end
    
    subgraph "Multi-Modal Processing Engine"
        subgraph "AI/ML Models"
            VADModel[ðŸ¤– Voice Activity Detection Model]
            FaceRecognitionModel[ðŸ‘¤ Face Recognition Model]
            BehaviorAnalysisModel[ðŸ“Š Behavior Analysis Model]
            AnomalyDetectionModel[ðŸš¨ Anomaly Detection Model]
            RiskAssessmentModel[âš–ï¸ Risk Assessment Model]
        end
        
        subgraph "Data Fusion Layer"
            ModalityFusion[ðŸ”— Modality Fusion Engine]
            TemporalAlignment[â° Temporal Alignment]
            ContextAggregation[ðŸ“‹ Context Aggregation]
            FeatureExtraction[ðŸŽ¯ Feature Extraction]
            PatternMatching[ðŸ” Pattern Matching]
        end
        
        subgraph "Decision Engine"
            RuleEngine[ðŸ“ Rule-based Engine]
            MLClassifier[ðŸ§  ML Classifier]
            ThresholdManager[âš–ï¸ Threshold Manager]
            ConfidenceScoring[ðŸ“Š Confidence Scoring]
            ActionDecision[ðŸŽ¯ Action Decision]
        end
    end
    
    subgraph "Output Modalities"
        subgraph "Visual Output"
            UIAlerts[ðŸš¨ UI Alerts]
            ProgressIndicators[ðŸ“Š Progress Indicators]
            StatusDisplays[ðŸ“‹ Status Displays]
            ViolationOverlays[âš ï¸ Violation Overlays]
            CameraPreview[ðŸ“¹ Camera Preview]
        end
        
        subgraph "Audio Output"
            AudioAlerts[ðŸ”Š Audio Alerts]
            VoiceWarnings[ðŸ—£ï¸ Voice Warnings]
            SystemSounds[ðŸŽµ System Sounds]
            AudioFeedback[ðŸŽ¤ Audio Feedback]
        end
        
        subgraph "Haptic Output"
            Vibrations[ðŸ“³ Vibrations]
            ScreenShake[ðŸ“± Screen Shake]
            CursorEffects[ðŸ–±ï¸ Cursor Effects]
        end
        
        subgraph "Data Output"
            RealTimeData[ðŸ“Š Real-time Data Stream]
            ViolationLogs[ðŸ“ Violation Logs]
            BehaviorMetrics[ðŸ“ˆ Behavior Metrics]
            SessionRecords[ðŸ’¾ Session Records]
            EvidenceFiles[ðŸ—„ï¸ Evidence Files]
        end
    end
    
    subgraph "Storage & Communication"
        subgraph "Local Storage"
            LocalCache[ðŸ’¾ Local Cache]
            TempStorage[ðŸ“ Temporary Storage]
            SessionStorage[ðŸ—ƒï¸ Session Storage]
        end
        
        subgraph "Cloud Storage"
            FirebaseDB[â˜ï¸ Firebase Database]
            FileStorage[ðŸ“ File Storage]
            RealTimeDB[âš¡ Real-time Database]
        end
        
        subgraph "Communication Channels"
            WebRTC[ðŸ“¡ WebRTC]
            WebSockets[ðŸ”Œ WebSockets]
            HTTPRequests[ðŸŒ HTTP Requests]
            EventStreams[ðŸ“Š Event Streams]
        end
    end
    
    %% Input to Processing Connections
    Camera --> VADModel
    Camera --> FaceRecognitionModel
    Microphone --> VADModel
    VoiceDetection --> VADModel
    MouseMovement --> BehaviorAnalysisModel
    ClickPatterns --> BehaviorAnalysisModel
    KeyboardInput --> BehaviorAnalysisModel
    TabSwitching --> AnomalyDetectionModel
    
    %% Processing Internal Connections
    VADModel --> ModalityFusion
    FaceRecognitionModel --> ModalityFusion
    BehaviorAnalysisModel --> ModalityFusion
    AnomalyDetectionModel --> ModalityFusion
    
    ModalityFusion --> TemporalAlignment
    TemporalAlignment --> ContextAggregation
    ContextAggregation --> FeatureExtraction
    FeatureExtraction --> PatternMatching
    
    PatternMatching --> RuleEngine
    PatternMatching --> MLClassifier
    RuleEngine --> ThresholdManager
    MLClassifier --> ConfidenceScoring
    ThresholdManager --> ActionDecision
    ConfidenceScoring --> ActionDecision
    
    ActionDecision --> RiskAssessmentModel
    RiskAssessmentModel --> ActionDecision
    
    %% Processing to Output Connections
    ActionDecision --> UIAlerts
    ActionDecision --> AudioAlerts
    ActionDecision --> Vibrations
    ActionDecision --> RealTimeData
    ActionDecision --> ViolationLogs
    
    RiskAssessmentModel --> StatusDisplays
    BehaviorAnalysisModel --> BehaviorMetrics
    ModalityFusion --> SessionRecords
    
    %% Storage Connections
    ViolationLogs --> LocalCache
    SessionRecords --> SessionStorage
    EvidenceFiles --> TempStorage
    
    LocalCache --> FirebaseDB
    SessionStorage --> RealTimeDB
    TempStorage --> FileStorage
    
    %% Communication Connections
    RealTimeData --> WebRTC
    ViolationLogs --> WebSockets
    SessionRecords --> HTTPRequests
    BehaviorMetrics --> EventStreams
    
    %% Styling
    classDef inputLayer fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef processingLayer fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef outputLayer fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef storageLayer fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    
    class Camera,ScreenCapture,FaceDetection,GestureRecognition,EyeTracking,Microphone,VoiceDetection,SpeechRecognition,AudioAnalysis,NoiseDetection,KeyboardInput,TextAnalysis,TypingBehavior,LanguageDetection,MouseMovement,ClickPatterns,ScrollBehavior,WindowInteraction,TabSwitching,DeviceOrientation,ScreenResolution,BatteryStatus,NetworkStatus,SystemResources inputLayer
    
    class VADModel,FaceRecognitionModel,BehaviorAnalysisModel,AnomalyDetectionModel,RiskAssessmentModel,ModalityFusion,TemporalAlignment,ContextAggregation,FeatureExtraction,PatternMatching,RuleEngine,MLClassifier,ThresholdManager,ConfidenceScoring,ActionDecision processingLayer
    
    class UIAlerts,ProgressIndicators,StatusDisplays,ViolationOverlays,CameraPreview,AudioAlerts,VoiceWarnings,SystemSounds,AudioFeedback,Vibrations,ScreenShake,CursorEffects,RealTimeData,ViolationLogs,BehaviorMetrics,SessionRecords,EvidenceFiles outputLayer
    
    class LocalCache,TempStorage,SessionStorage,FirebaseDB,FileStorage,RealTimeDB,WebRTC,WebSockets,HTTPRequests,EventStreams storageLayer
```

## Multi-Modal Data Flow Architecture

```mermaid
flowchart LR
    subgraph "Sensory Input Layer"
        subgraph "Visual Sensors"
            V1[ðŸ“· Front Camera]
            V2[ðŸ–¥ï¸ Screen Monitor]
            V3[ðŸ‘ï¸ Eye Tracker]
            V4[ðŸ‘‹ Gesture Sensor]
        end
        
        subgraph "Audio Sensors"
            A1[ðŸŽ¤ Primary Microphone]
            A2[ðŸ”Š System Audio]
            A3[ðŸŽ§ Headphone Monitor]
            A4[ðŸ“» Ambient Audio]
        end
        
        subgraph "Interaction Sensors"
            I1[âŒ¨ï¸ Keyboard Sensor]
            I2[ðŸ–±ï¸ Mouse Sensor]
            I3[ðŸ‘† Touch Sensor]
            I4[ðŸªŸ Window Sensor]
        end
        
        subgraph "Context Sensors"
            C1[ðŸ“± Device Context]
            C2[ðŸŒ Network Context]
            C3[âš¡ System Context]
            C4[ðŸ”‹ Power Context]
        end
    end
    
    subgraph "Feature Extraction Layer"
        subgraph "Visual Features"
            VF1[ðŸ‘¤ Face Features]
            VF2[ðŸ‘ï¸ Gaze Features]
            VF3[ðŸŽ­ Expression Features]
            VF4[ðŸ“ Pose Features]
        end
        
        subgraph "Audio Features"
            AF1[ðŸŽµ Spectral Features]
            AF2[ðŸ—£ï¸ Voice Features]
            AF3[ðŸ”Š Volume Features]
            AF4[â±ï¸ Temporal Features]
        end
        
        subgraph "Behavioral Features"
            BF1[âš¡ Typing Patterns]
            BF2[ðŸ–±ï¸ Mouse Patterns]
            BF3[â° Timing Patterns]
            BF4[ðŸ”„ Interaction Patterns]
        end
        
        subgraph "Contextual Features"
            CF1[ðŸ“Š Usage Patterns]
            CF2[ðŸŒ Network Patterns]
            CF3[âš™ï¸ System Patterns]
            CF4[ðŸ”‹ Resource Patterns]
        end
    end
    
    subgraph "Fusion & Analysis Layer"
        subgraph "Multi-Modal Fusion"
            MF1[ðŸ”— Early Fusion]
            MF2[ðŸŽ¯ Late Fusion]
            MF3[âš–ï¸ Decision Fusion]
            MF4[ðŸ“Š Feature Fusion]
        end
        
        subgraph "AI/ML Processing"
            ML1[ðŸ§  Deep Learning Models]
            ML2[ðŸ“ˆ Statistical Models]
            ML3[ðŸŽ¯ Classification Models]
            ML4[ðŸš¨ Anomaly Detection]
        end
        
        subgraph "Rule-Based Processing"
            RB1[ðŸ“ Threshold Rules]
            RB2[â° Temporal Rules]
            RB3[ðŸ”— Correlation Rules]
            RB4[ðŸŽ¯ Context Rules]
        end
    end
    
    subgraph "Decision & Action Layer"
        subgraph "Risk Assessment"
            RA1[ðŸ“Š Risk Scoring]
            RA2[âš–ï¸ Confidence Weighting]
            RA3[ðŸŽ¯ Threat Classification]
            RA4[ðŸ“ˆ Trend Analysis]
        end
        
        subgraph "Action Selection"
            AS1[âš ï¸ Warning Actions]
            AS2[ðŸ“¸ Evidence Collection]
            AS3[ðŸš« Blocking Actions]
            AS4[ðŸ“Š Reporting Actions]
        end
    end
    
    subgraph "Output & Feedback Layer"
        subgraph "Student Feedback"
            SF1[ðŸš¨ Visual Alerts]
            SF2[ðŸ”Š Audio Warnings]
            SF3[ðŸ“³ Haptic Feedback]
            SF4[ðŸ”’ Interface Locks]
        end
        
        subgraph "Teacher Dashboard"
            TD1[ðŸ‘ï¸ Real-time Monitor]
            TD2[ðŸ“Š Analytics Dashboard]
            TD3[ðŸ“¸ Evidence Viewer]
            TD4[ðŸ“ˆ Behavior Reports]
        end
        
        subgraph "System Actions"
            SA1[ðŸ’¾ Data Storage]
            SA2[ðŸ“¡ Real-time Sync]
            SA3[ðŸš« Auto Disqualification]
            SA4[ðŸ“‹ Audit Logging]
        end
    end
    
    %% Data Flow Connections
    V1 --> VF1
    V2 --> VF2
    V3 --> VF3
    V4 --> VF4
    
    A1 --> AF1
    A2 --> AF2
    A3 --> AF3
    A4 --> AF4
    
    I1 --> BF1
    I2 --> BF2
    I3 --> BF3
    I4 --> BF4
    
    C1 --> CF1
    C2 --> CF2
    C3 --> CF3
    C4 --> CF4
    
    VF1 --> MF1
    VF2 --> MF1
    AF1 --> MF2
    AF2 --> MF2
    BF1 --> MF3
    BF2 --> MF3
    CF1 --> MF4
    CF2 --> MF4
    
    MF1 --> ML1
    MF2 --> ML2
    MF3 --> ML3
    MF4 --> ML4
    
    VF3 --> RB1
    AF3 --> RB2
    BF3 --> RB3
    CF3 --> RB4
    
    ML1 --> RA1
    ML2 --> RA2
    ML3 --> RA3
    ML4 --> RA4
    
    RB1 --> RA1
    RB2 --> RA2
    RB3 --> RA3
    RB4 --> RA4
    
    RA1 --> AS1
    RA2 --> AS2
    RA3 --> AS3
    RA4 --> AS4
    
    AS1 --> SF1
    AS1 --> SF2
    AS2 --> SF3
    AS3 --> SF4
    
    AS1 --> TD1
    AS2 --> TD2
    AS3 --> TD3
    AS4 --> TD4
    
    AS1 --> SA1
    AS2 --> SA2
    AS3 --> SA3
    AS4 --> SA4
    
    %% Styling
    classDef inputLayer fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef featureLayer fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef fusionLayer fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef decisionLayer fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef outputLayer fill:#fce4ec,stroke:#e91e63,stroke-width:2px
    
    class V1,V2,V3,V4,A1,A2,A3,A4,I1,I2,I3,I4,C1,C2,C3,C4 inputLayer
    class VF1,VF2,VF3,VF4,AF1,AF2,AF3,AF4,BF1,BF2,BF3,BF4,CF1,CF2,CF3,CF4 featureLayer
    class MF1,MF2,MF3,MF4,ML1,ML2,ML3,ML4,RB1,RB2,RB3,RB4 fusionLayer
    class RA1,RA2,RA3,RA4,AS1,AS2,AS3,AS4 decisionLayer
    class SF1,SF2,SF3,SF4,TD1,TD2,TD3,TD4,SA1,SA2,SA3,SA4 outputLayer
```

## Multi-Modal Integration Architecture

```mermaid
graph TB
    subgraph "Multi-Modal Input Processing"
        subgraph "Synchronous Inputs"
            SyncVideo[ðŸ“¹ Video Stream (30fps)]
            SyncAudio[ðŸŽ¤ Audio Stream (44.1kHz)]
            SyncMouse[ðŸ–±ï¸ Mouse Events (Real-time)]
            SyncKeyboard[âŒ¨ï¸ Keyboard Events (Real-time)]
        end
        
        subgraph "Asynchronous Inputs"
            AsyncDevice[ðŸ“± Device Status (5s interval)]
            AsyncNetwork[ðŸŒ Network Status (10s interval)]
            AsyncExtensions[ðŸ” Extension Scan (15s interval)]
            AsyncSystem[âš™ï¸ System Resources (30s interval)]
        end
        
        subgraph "Event-Driven Inputs"
            EventFocus[ðŸ‘ï¸ Focus Change Events]
            EventFullscreen[ðŸ”’ Fullscreen Events]
            EventPermission[ðŸ” Permission Events]
            EventError[âŒ Error Events]
        end
    end
    
    subgraph "Temporal Synchronization Engine"
        subgraph "Time Alignment"
            TimeSync[â° Time Synchronization]
            BufferManager[ðŸ“Š Buffer Manager]
            FrameAlignment[ðŸŽ¬ Frame Alignment]
            EventQueue[ðŸ“‹ Event Queue]
        end
        
        subgraph "Data Correlation"
            CrossModal[ðŸ”— Cross-Modal Correlation]
            TemporalWindow[â±ï¸ Temporal Window Analysis]
            CausalityDetection[ðŸŽ¯ Causality Detection]
            PatternAlignment[ðŸ“ Pattern Alignment]
        end
    end
    
    subgraph "Multi-Modal AI Engine"
        subgraph "Specialized Models"
            VisionModel[ðŸ‘ï¸ Computer Vision Model]
            AudioModel[ðŸŽµ Audio Processing Model]
            BehaviorModel[ðŸ“Š Behavior Analysis Model]
            ContextModel[ðŸ§  Context Understanding Model]
        end
        
        subgraph "Fusion Models"
            EarlyFusion[ðŸ”— Early Fusion Network]
            LateFusion[ðŸŽ¯ Late Fusion Network]
            AttentionMechanism[ðŸŽ¯ Attention Mechanism]
            EnsembleModel[ðŸ¤ Ensemble Model]
        end
        
        subgraph "Decision Models"
            ClassificationHead[ðŸŽ¯ Classification Head]
            RegressionHead[ðŸ“ˆ Regression Head]
            AnomalyHead[ðŸš¨ Anomaly Detection Head]
            ConfidenceHead[ðŸ“Š Confidence Estimation Head]
        end
    end
    
    subgraph "Multi-Modal Output Generation"
        subgraph "Adaptive Responses"
            VisualResponse[ðŸ‘ï¸ Visual Response Generator]
            AudioResponse[ðŸ”Š Audio Response Generator]
            HapticResponse[ðŸ“³ Haptic Response Generator]
            SystemResponse[âš™ï¸ System Response Generator]
        end
        
        subgraph "Personalized Feedback"
            StudentProfile[ðŸ‘¤ Student Profile Adapter]
            LearningStyle[ðŸŽ“ Learning Style Adapter]
            AccessibilityAdapter[â™¿ Accessibility Adapter]
            LanguageAdapter[ðŸŒ Language Adapter]
        end
        
        subgraph "Context-Aware Output"
            ExamContext[ðŸ“ Exam Context Adapter]
            TimeContext[â° Time Context Adapter]
            StressContext[ðŸ˜° Stress Level Adapter]
            PerformanceContext[ðŸ“Š Performance Adapter]
        end
    end
    
    subgraph "Feedback Loop & Learning"
        subgraph "Performance Monitoring"
            AccuracyTracker[ðŸŽ¯ Accuracy Tracker]
            FalsePositiveTracker[âŒ False Positive Tracker]
            ResponseTimeTracker[â±ï¸ Response Time Tracker]
            UserSatisfactionTracker[ðŸ˜Š User Satisfaction Tracker]
        end
        
        subgraph "Model Adaptation"
            OnlineLearning[ðŸ“š Online Learning]
            ModelUpdater[ðŸ”„ Model Updater]
            ThresholdAdjuster[âš–ï¸ Threshold Adjuster]
            FeatureSelector[ðŸŽ¯ Feature Selector]
        end
    end
    
    %% Input Processing Connections
    SyncVideo --> TimeSync
    SyncAudio --> TimeSync
    SyncMouse --> BufferManager
    SyncKeyboard --> BufferManager
    
    AsyncDevice --> EventQueue
    AsyncNetwork --> EventQueue
    AsyncExtensions --> EventQueue
    AsyncSystem --> EventQueue
    
    EventFocus --> FrameAlignment
    EventFullscreen --> FrameAlignment
    EventPermission --> FrameAlignment
    EventError --> FrameAlignment
    
    %% Synchronization Connections
    TimeSync --> CrossModal
    BufferManager --> TemporalWindow
    FrameAlignment --> CausalityDetection
    EventQueue --> PatternAlignment
    
    CrossModal --> VisionModel
    TemporalWindow --> AudioModel
    CausalityDetection --> BehaviorModel
    PatternAlignment --> ContextModel
    
    %% AI Processing Connections
    VisionModel --> EarlyFusion
    AudioModel --> EarlyFusion
    BehaviorModel --> LateFusion
    ContextModel --> LateFusion
    
    EarlyFusion --> AttentionMechanism
    LateFusion --> AttentionMechanism
    AttentionMechanism --> EnsembleModel
    
    EnsembleModel --> ClassificationHead
    EnsembleModel --> RegressionHead
    EnsembleModel --> AnomalyHead
    EnsembleModel --> ConfidenceHead
    
    %% Output Generation Connections
    ClassificationHead --> VisualResponse
    RegressionHead --> AudioResponse
    AnomalyHead --> HapticResponse
    ConfidenceHead --> SystemResponse
    
    VisualResponse --> StudentProfile
    AudioResponse --> LearningStyle
    HapticResponse --> AccessibilityAdapter
    SystemResponse --> LanguageAdapter
    
    StudentProfile --> ExamContext
    LearningStyle --> TimeContext
    AccessibilityAdapter --> StressContext
    LanguageAdapter --> PerformanceContext
    
    %% Feedback Connections
    ExamContext --> AccuracyTracker
    TimeContext --> FalsePositiveTracker
    StressContext --> ResponseTimeTracker
    PerformanceContext --> UserSatisfactionTracker
    
    AccuracyTracker --> OnlineLearning
    FalsePositiveTracker --> ModelUpdater
    ResponseTimeTracker --> ThresholdAdjuster
    UserSatisfactionTracker --> FeatureSelector
    
    OnlineLearning --> VisionModel
    ModelUpdater --> AudioModel
    ThresholdAdjuster --> BehaviorModel
    FeatureSelector --> ContextModel
    
    %% Styling
    classDef inputLayer fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px
    classDef syncLayer fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef aiLayer fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef outputLayer fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef feedbackLayer fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    
    class SyncVideo,SyncAudio,SyncMouse,SyncKeyboard,AsyncDevice,AsyncNetwork,AsyncExtensions,AsyncSystem,EventFocus,EventFullscreen,EventPermission,EventError inputLayer
    
    class TimeSync,BufferManager,FrameAlignment,EventQueue,CrossModal,TemporalWindow,CausalityDetection,PatternAlignment syncLayer
    
    class VisionModel,AudioModel,BehaviorModel,ContextModel,EarlyFusion,LateFusion,AttentionMechanism,EnsembleModel,ClassificationHead,RegressionHead,AnomalyHead,ConfidenceHead aiLayer
    
    class VisualResponse,AudioResponse,HapticResponse,SystemResponse,StudentProfile,LearningStyle,AccessibilityAdapter,LanguageAdapter,ExamContext,TimeContext,StressContext,PerformanceContext outputLayer
    
    class AccuracyTracker,FalsePositiveTracker,ResponseTimeTracker,UserSatisfactionTracker,OnlineLearning,ModelUpdater,ThresholdAdjuster,FeatureSelector feedbackLayer
```

## Multi-Modal Security Architecture

```mermaid
graph TB
    subgraph "Multi-Modal Security Layers"
        subgraph "Layer 1: Device Security"
            L1_1[ðŸ“± Device Type Validation]
            L1_2[ðŸ–¥ï¸ Screen Configuration Check]
            L1_3[ðŸ“ Resolution Compliance]
            L1_4[ðŸ”‹ Hardware Capability Check]
        end
        
        subgraph "Layer 2: Permission Security"
            L2_1[ðŸ“· Camera Access Control]
            L2_2[ðŸŽ¤ Microphone Access Control]
            L2_3[ðŸ”’ Fullscreen Enforcement]
            L2_4[ðŸ‘ï¸ Focus Lock Mechanism]
        end
        
        subgraph "Layer 3: Browser Security"
            L3_1[ðŸ› ï¸ DevTools Detection & Block]
            L3_2[ðŸ“‹ Copy/Paste Prevention]
            L3_3[âŒ¨ï¸ Keyboard Shortcut Block]
            L3_4[ðŸ”„ Tab Switch Detection]
        end
        
        subgraph "Layer 4: Extension Security"
            L4_1[ðŸ¤– AI Assistant Detection]
            L4_2[ðŸŒ Translation Tool Detection]
            L4_3[ðŸ’¬ Communication Tool Detection]
            L4_4[ðŸ“š Academic Tool Detection]
        end
        
        subgraph "Layer 5: Behavioral Security"
            L5_1[ðŸ–±ï¸ Mouse Pattern Analysis]
            L5_2[âŒ¨ï¸ Typing Pattern Analysis]
            L5_3[â° Timing Anomaly Detection]
            L5_4[ðŸŽ¯ Answer Pattern Analysis]
        end
        
        subgraph "Layer 6: Biometric Security"
            L6_1[ðŸ‘¤ Face Recognition]
            L6_2[ðŸ‘ï¸ Eye Movement Tracking]
            L6_3[ðŸ—£ï¸ Voice Print Analysis]
            L6_4[âœ‹ Gesture Authentication]
        end
    end
    
    subgraph "Multi-Modal Threat Detection"
        subgraph "Threat Categories"
            T1[ðŸ¤– AI-Assisted Cheating]
            T2[ðŸ‘¥ Collaboration Cheating]
            T3[ðŸ“± Device-Based Cheating]
            T4[ðŸ”„ Context Switching Cheating]
            T5[ðŸ“‹ Content Theft Cheating]
        end
        
        subgraph "Detection Algorithms"
            D1[ðŸ§  Neural Network Classifier]
            D2[ðŸ“Š Statistical Anomaly Detector]
            D3[ðŸ“ Rule-Based Validator]
            D4[ðŸŽ¯ Pattern Matcher]
            D5[âš–ï¸ Ensemble Predictor]
        end
        
        subgraph "Evidence Collection"
            E1[ðŸ“¸ Visual Evidence Capture]
            E2[ðŸŽ¤ Audio Evidence Recording]
            E3[ðŸ“Š Behavioral Evidence Logging]
            E4[ðŸ• Temporal Evidence Tracking]
            E5[ðŸ”— Contextual Evidence Linking]
        end
    end
    
    subgraph "Multi-Modal Response System"
        subgraph "Immediate Responses"
            R1[ðŸš¨ Real-time Alerts]
            R2[ðŸ”’ Immediate Blocking]
            R3[ðŸ“¸ Evidence Capture]
            R4[âš ï¸ Warning Display]
        end
        
        subgraph "Adaptive Responses"
            A1[ðŸ“ˆ Escalating Warnings]
            A2[ðŸŽ¯ Targeted Interventions]
            A3[ðŸ”„ Dynamic Threshold Adjustment]
            A4[ðŸ“Š Personalized Feedback]
        end
        
        subgraph "Preventive Responses"
            P1[ðŸ›¡ï¸ Proactive Blocking]
            P2[ðŸ” Enhanced Monitoring]
            P3[ðŸ“‹ Additional Verification]
            P4[â° Time Restrictions]
        end
    end
    
    subgraph "Multi-Modal Analytics"
        subgraph "Real-time Analytics"
            RT1[ðŸ“Š Live Threat Assessment]
            RT2[ðŸ‘ï¸ Continuous Risk Monitoring]
            RT3[ðŸŽ¯ Dynamic Pattern Recognition]
            RT4[âš¡ Instant Decision Making]
        end
        
        subgraph "Historical Analytics"
            H1[ðŸ“ˆ Trend Analysis]
            H2[ðŸ” Pattern Discovery]
            H3[ðŸ“Š Performance Metrics]
            H4[ðŸŽ¯ Accuracy Assessment]
        end
        
        subgraph "Predictive Analytics"
            PR1[ðŸ”® Threat Prediction]
            PR2[ðŸ“ˆ Risk Forecasting]
            PR3[ðŸŽ¯ Behavior Prediction]
            PR4[âš–ï¸ Outcome Estimation]
        end
    end
    
    %% Security Layer Connections
    L1_1 --> T3
    L1_2 --> T3
    L2_1 --> T4
    L2_2 --> T4
    L3_1 --> T5
    L3_2 --> T5
    L4_1 --> T1
    L4_2 --> T1
    L5_1 --> T2
    L5_2 --> T2
    L6_1 --> T2
    L6_2 --> T2
    
    %% Threat to Detection Connections
    T1 --> D1
    T2 --> D2
    T3 --> D3
    T4 --> D4
    T5 --> D5
    
    %% Detection to Evidence Connections
    D1 --> E1
    D2 --> E2
    D3 --> E3
    D4 --> E4
    D5 --> E5
    
    %% Evidence to Response Connections
    E1 --> R1
    E2 --> R2
    E3 --> R3
    E4 --> R4
    
    R1 --> A1
    R2 --> A2
    R3 --> A3
    R4 --> A4
    
    A1 --> P1
    A2 --> P2
    A3 --> P3
    A4 --> P4
    
    %% Analytics Connections
    R1 --> RT1
    R2 --> RT2
    R3 --> RT3
    R4 --> RT4
    
    RT1 --> H1
    RT2 --> H2
    RT3 --> H3
    RT4 --> H4
    
    H1 --> PR1
    H2 --> PR2
    H3 --> PR3
    H4 --> PR4
    
    %% Feedback Loops
    PR1 --> L4_1
    PR2 --> L5_1
    PR3 --> L6_1
    PR4 --> D1
    
    %% Styling
    classDef securityLayer fill:#ffebee,stroke:#c62828,stroke-width:2px
    classDef threatLayer fill:#fce4ec,stroke:#e91e63,stroke-width:2px
    classDef responseLayer fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef analyticsLayer fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    
    class L1_1,L1_2,L1_3,L1_4,L2_1,L2_2,L2_3,L2_4,L3_1,L3_2,L3_3,L3_4,L4_1,L4_2,L4_3,L4_4,L5_1,L5_2,L5_3,L5_4,L6_1,L6_2,L6_3,L6_4 securityLayer
    
    class T1,T2,T3,T4,T5,D1,D2,D3,D4,D5,E1,E2,E3,E4,E5 threatLayer
    
    class R1,R2,R3,R4,A1,A2,A3,A4,P1,P2,P3,P4 responseLayer
    
    class RT1,RT2,RT3,RT4,H1,H2,H3,H4,PR1,PR2,PR3,PR4 analyticsLayer
```

## Cara Menggunakan Diagram

1. **Salin kode diagram** yang ingin Anda lihat
2. **Buka** https://mermaid.js.org/
3. **Paste kode** di editor
4. **Klik "Render"** untuk melihat diagram
5. **Export** sebagai PNG/SVG jika diperlukan

## Penjelasan Multi-Modal Architecture

### **ðŸŽ¯ Input Modalities:**
- **Visual:** Camera, screen capture, face detection, gesture recognition
- **Audio:** Microphone, voice detection, speech recognition, audio analysis
- **Text:** Keyboard input, text analysis, typing behavior
- **Behavioral:** Mouse movement, click patterns, scroll behavior
- **Device:** Orientation, resolution, battery, network status

### **ðŸ§  Processing Engine:**
- **AI/ML Models:** VAD, face recognition, behavior analysis, anomaly detection
- **Data Fusion:** Multi-modal fusion dengan temporal alignment
- **Decision Engine:** Rule-based + ML classifier dengan confidence scoring

### **ðŸ“¤ Output Modalities:**
- **Visual:** UI alerts, status displays, violation overlays
- **Audio:** Audio alerts, voice warnings, system sounds
- **Haptic:** Vibrations, screen shake, cursor effects
- **Data:** Real-time streams, logs, metrics, evidence files

### **ðŸ”„ Feedback Loop:**
- **Performance monitoring** untuk accuracy dan false positives
- **Model adaptation** dengan online learning
- **Threshold adjustment** berdasarkan performance
- **Feature selection** untuk optimasi

Arsitektur ini menunjukkan bagaimana sistem mengintegrasikan berbagai modalitas input untuk deteksi kecurangan yang komprehensif dan menghasilkan response yang adaptif sesuai konteks.